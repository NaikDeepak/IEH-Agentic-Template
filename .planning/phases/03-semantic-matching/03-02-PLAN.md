---
phase: 03-semantic-matching
plan: 02
type: execute
wave: 2
depends_on: [03-01]
files_modified:
  - functions/index.js
autonomous: true
must_haves:
  truths:
    - "Search queries are expanded by LLM before embedding"
    - "Search results include a matchScore (0-100%)"
    - "Short queries (e.g. 'React') become rich semantic descriptions"
  artifacts:
    - path: "functions/index.js"
      provides: "Intelligence layer"
      contains: "expandQuery"
  key_links:
    - from: "searchJobsHandler"
      to: "gemini-2.0-flash"
      via: "generateContent"
---

<objective>
Inject intelligence into the search process by implementing Query Expansion (RAG-lite) and Match Scoring.

Purpose: Improve search recall and relevance. Raw keyword-to-vector often fails on short queries. Expansion bridges the gap between "React" (user query) and "Frontend developer with React.js ecosystem experience" (target).
Output: Enhanced `functions/index.js` that expands queries and calculates user-friendly match scores.
</objective>

<execution_context>
@/Users/deepaknaik/.claude/get-shit-done/workflows/execute-plan.md
@/Users/deepaknaik/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/03-semantic-matching/03-CONTEXT.md
@functions/index.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Query Expansion Helper</name>
  <files>functions/index.js</files>
  <action>
    Add `expandQuery(originalQuery, context, apiKey)` function to `functions/index.js`.

    Logic:
    1. Use `gemini-2.0-flash` (fast/cheap).
    2. Prompt: "You are an expert IT recruiter in India. Expand this search query into a detailed semantic description of the ideal candidate/job. Include related skills, tools, and alternative titles. Keep it under 100 words. Query: {originalQuery}"
    3. Context param: "finding a candidate" or "finding a job" to tune the prompt.
    4. Return the expanded text.
    5. Fallback: If LLM fails, return original query.
  </action>
  <verify>grep "async function expandQuery" functions/index.js</verify>
  <done>expandQuery helper implemented</done>
</task>

<task type="auto">
  <name>Task 2: Integrate Expansion and Scoring</name>
  <files>functions/index.js</files>
  <action>
    Update `searchJobsHandler` and `searchCandidatesHandler`:

    1. Call `expandQuery` before generating embedding.
       - `searchJobs`: Context "finding a job" (User is candidate) -> wait, actually "finding a job matching these criteria".
       - `searchCandidates`: Context "finding a candidate" (User is employer).

    2. Log the expansion for debugging (console.log).

    3. Generate embedding from *expanded* text.

    4. Post-process Firestore results:
       - Firestore returns `distance` (Cosine Distance).
       - Calculate `matchScore = (1 - distance) * 100`.
       - Round to integer.
       - Inject `matchScore` into the returned item object.
  </action>
  <verify>grep "matchScore =" functions/index.js</verify>
  <done>Search handlers use expanded queries and return match scores</done>
</task>

</tasks>

<verification>
Manual verification:
Review the `matchScore` formula: `(1 - cosine_distance) * 100`.
Ensure `expandQuery` has a try/catch block to prevent search failure if GenAI is glitchy.
</verification>

<success_criteria>
- [ ] `expandQuery` implemented with `gemini-2.0-flash`
- [ ] Search handlers call expansion before embedding
- [ ] Response objects contain `matchScore` field
</success_criteria>

<output>
After completion, create `.planning/phases/03-semantic-matching/03-02-SUMMARY.md`
</output>
